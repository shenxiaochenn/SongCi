{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81d4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Mydataset_plip2\n",
    "from torch.utils.data import DataLoader\n",
    "from load_model import model_fusion\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb00948",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"internal_corhort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e96c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>case</th>\n",
       "      <th>kind</th>\n",
       "      <th>description</th>\n",
       "      <th>disease</th>\n",
       "      <th>prototype</th>\n",
       "      <th>pro_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a21-1884_brain0.csv</td>\n",
       "      <td>a21-1884</td>\n",
       "      <td>brain</td>\n",
       "      <td>Scattered punctate hemorrhage is observed unde...</td>\n",
       "      <td>The hemorrhage under the scalp</td>\n",
       "      <td>{830: 1259, 555: 567, 786: 504, 535: 497, 857:...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      case   kind  \\\n",
       "0  a21-1884_brain0.csv  a21-1884  brain   \n",
       "\n",
       "                                         description  \\\n",
       "0  Scattered punctate hemorrhage is observed unde...   \n",
       "\n",
       "                          disease  \\\n",
       "0  The hemorrhage under the scalp   \n",
       "\n",
       "                                           prototype  pro_num  \n",
       "0  {830: 1259, 555: 567, 786: 504, 535: 497, 857:...       80  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1) # the protoype  embedding get from step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbfe716",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = Mydataset_plip2(\"internal_corhort.csv\", randomm=False)\n",
    "trainloader = DataLoader(dd, batch_size=1, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1a87a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_fusion(depth=2,noise_ratio=0.0, gate=True,num_em=True)\n",
    "model.load_state_dict(torch.load(\"fusion_checkpoint.pth\",map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a67641",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fusionblock2(\n",
       "  (text_model): CLIPModel(\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (text_model): CLIPTextTransformer(\n",
       "      (invertible_adapters): ModuleDict()\n",
       "      (embeddings): CLIPTextEmbeddings(\n",
       "        (token_embedding): Embedding(49408, 512)\n",
       "        (position_embedding): Embedding(77, 512)\n",
       "      )\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (1): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (2): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (3): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (4): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (5): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (6): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (7): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (8): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (9): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (10): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (11): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "        (position_embedding): Embedding(50, 768)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (1): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (2): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (3): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (4): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (5): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (6): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (7): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (8): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (9): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (10): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (11): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "    (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (disease_model): CLIPModel(\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (text_model): CLIPTextTransformer(\n",
       "      (invertible_adapters): ModuleDict()\n",
       "      (embeddings): CLIPTextEmbeddings(\n",
       "        (token_embedding): Embedding(49408, 512)\n",
       "        (position_embedding): Embedding(77, 512)\n",
       "      )\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (1): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (2): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (3): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (4): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (5): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (6): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (7): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (8): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (9): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (10): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (11): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=512, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=512, out_features=2048, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=2048, out_features=512, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "        (position_embedding): Embedding(50, 768)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (1): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (2): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (3): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (4): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (5): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (6): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (7): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (8): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (9): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (10): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (11): CLIPEncoderLayer(\n",
       "            (self_attn): CLIPAttention(\n",
       "              (k_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(\n",
       "                in_features=768, out_features=3072, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (fc2): Linear(\n",
       "                in_features=3072, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): AdapterLayer(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "    (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (num_embed): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (project_text_to_img): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "  )\n",
       "  (cross_img_text): GatedCrossAttentionBlock(\n",
       "    (attn): CrossAttention(\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "      (to_kv): Linear(in_features=256, out_features=1024, bias=False)\n",
       "      (to_out): Linear(in_features=512, out_features=256, bias=False)\n",
       "    )\n",
       "    (ff): Sequential(\n",
       "      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=1024, out_features=256, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (cross_text_img): GatedCrossAttentionBlock(\n",
       "    (attn): CrossAttention(\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "      (to_kv): Linear(in_features=256, out_features=1024, bias=False)\n",
       "      (to_out): Linear(in_features=512, out_features=256, bias=False)\n",
       "    )\n",
       "    (ff): Sequential(\n",
       "      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=1024, out_features=256, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (transformer): ModuleList(\n",
       "    (0): GatedCrossAttentionBlock(\n",
       "      (attn): CrossAttention(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "        (to_kv): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (to_out): Linear(in_features=512, out_features=256, bias=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): GatedCrossAttentionBlock(\n",
       "      (attn): CrossAttention(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "        (to_kv): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (to_out): Linear(in_features=512, out_features=256, bias=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=512, bias=False)\n",
       "  (emmeder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=1024, bias=False)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7602b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a set of candidate diagnoses, we can use the diagnosis of data as an example of a candidate in this context.\n",
    "for it, (tokens_disease,tokens_description,img,img_num) in enumerate(trainloader):\n",
    "    tokens_description[\"input_ids\"] = tokens_description[\"input_ids\"].squeeze(1).cuda(non_blocking=True)\n",
    "    tokens_description[\"attention_mask\"] = tokens_description[\"attention_mask\"].squeeze(1).cuda(non_blocking=True)\n",
    "    tokens_disease[\"input_ids\"] = tokens_disease[\"input_ids\"].squeeze(1).cuda(non_blocking=True)\n",
    "    tokens_disease[\"attention_mask\"] = tokens_disease[\"attention_mask\"].squeeze(1).cuda(non_blocking=True)\n",
    "    _, _, _, img_text_out, disease, _ = model(img_p=img.cuda(non_blocking=True),text=tokens_description,img_num=img_num.cuda(non_blocking=True),disease=tokens_disease)\n",
    "    score = img_text_out.cpu().squeeze() @ disease.cpu().squeeze().t()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da0d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9173, grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(score) # Return the similarity between the fused embedding of the multimodal input and the target diagnosis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbdaccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have any candidate diagnoses, as an exsample, we provide commonly used diagnoses in forensic pathology here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b2ed382",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"disease.txt\", \"r\") as file:\n",
    "    my_list = [line.strip() for line in file]\n",
    "tokenizer = CLIPProcessor.from_pretrained(\"vinid/plip\").tokenizer\n",
    "token_disease = tokenizer(my_list, padding=\"max_length\", max_length=77, return_tensors=\"pt\")\n",
    "token_disease[\"input_ids\"] = token_disease[\"input_ids\"].cuda(non_blocking=True)\n",
    "token_disease[\"attention_mask\"] = token_disease[\"attention_mask\"].cuda(non_blocking=True)\n",
    "disease_model = CLIPModel.from_pretrained(\"vinid/plip\")\n",
    "disease_model.eval()\n",
    "disease_model.cuda()\n",
    "disease_rep = disease_model.get_text_features(**token_disease)\n",
    "disease_rep = F.normalize(disease_rep, dim=-1).cpu()\n",
    "for it, (tokens_disease,tokens_description,img,img_num) in enumerate(trainloader):\n",
    "    score_list=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens_description[\"input_ids\"] = tokens_description[\"input_ids\"].squeeze(1).cuda(non_blocking=True)\n",
    "        tokens_description[\"attention_mask\"] = tokens_description[\"attention_mask\"].squeeze(1).cuda(non_blocking=True)\n",
    "        for ind, (t_disease,t_attention) in enumerate(zip(token_disease[\"input_ids\"],token_disease[\"attention_mask\"])):\n",
    "            _, _, _, img_text_out, disease, attention_score = model(img_p=img.cuda(non_blocking=True),\n",
    "                                                                           text=tokens_description,\n",
    "                                                                           img_num=img_num.cuda(non_blocking=True),\n",
    "                                                                           disease={\"input_ids\":t_disease.unsqueeze(0),\"attention_mask\":t_attention.unsqueeze(0)})\n",
    "            score = img_text_out.cpu().squeeze() @ disease_rep[ind].t()\n",
    "            score_list.append(score)\n",
    "\n",
    "        score_array = np.array(score_list)\n",
    "\n",
    "\n",
    "        disease_name_max = [my_list[i] for i in score_array.argsort()[-1:][::-1].tolist()]  # top1\n",
    "        disease_name_top2 = [my_list[i] for i in score_array.argsort()[-2:][::-1].tolist()] # top2 \n",
    "        disease_name_top3 = [my_list[i] for i in score_array.argsort()[-3:][::-1].tolist()]  # top3 \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5446b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The hemorrhage under the scalp']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_name_max # best answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47e2d0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The hemorrhage under the scalp', 'Cerebral hemorrhage']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_name_top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40320865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The hemorrhage under the scalp',\n",
       " 'Cerebral hemorrhage',\n",
       " 'Cerebral congestion']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_name_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e22c61ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The hemorrhage under the scalp'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0,\"disease\"] # the groudtruth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53bdd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
